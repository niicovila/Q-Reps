
[34m[1mwandb[39m[22m: [33mWARNING[39m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
/Users/nicolasvila/miniconda3/lib/python3.11/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
Moviepy - Building video /Users/nicolasvila/workplace/uni/tfg_v2/tests/videos/CartPole-v1__cartpole__0__1709195828/rl-video-episode-0.mp4.
Moviepy - Writing video /Users/nicolasvila/workplace/uni/tfg_v2/tests/videos/CartPole-v1__cartpole__0__1709195828/rl-video-episode-0.mp4
Moviepy - Done !
Moviepy - video ready /Users/nicolasvila/workplace/uni/tfg_v2/tests/videos/CartPole-v1__cartpole__0__1709195828/rl-video-episode-0.mp4
Moviepy - Building video /Users/nicolasvila/workplace/uni/tfg_v2/tests/videos/CartPole-v1__cartpole__0__1709195828/rl-video-episode-1.mp4.
Moviepy - Writing video /Users/nicolasvila/workplace/uni/tfg_v2/tests/videos/CartPole-v1__cartpole__0__1709195828/rl-video-episode-1.mp4
Moviepy - Done !
Moviepy - video ready /Users/nicolasvila/workplace/uni/tfg_v2/tests/videos/CartPole-v1__cartpole__0__1709195828/rl-video-episode-1.mp4
Moviepy - Building video /Users/nicolasvila/workplace/uni/tfg_v2/tests/videos/CartPole-v1__cartpole__0__1709195828/rl-video-episode-8.mp4.
Moviepy - Writing video /Users/nicolasvila/workplace/uni/tfg_v2/tests/videos/CartPole-v1__cartpole__0__1709195828/rl-video-episode-8.mp4
Moviepy - Done !
Moviepy - video ready /Users/nicolasvila/workplace/uni/tfg_v2/tests/videos/CartPole-v1__cartpole__0__1709195828/rl-video-episode-8.mp4
Moviepy - Building video /Users/nicolasvila/workplace/uni/tfg_v2/tests/videos/CartPole-v1__cartpole__0__1709195828/rl-video-episode-27.mp4.
Moviepy - Writing video /Users/nicolasvila/workplace/uni/tfg_v2/tests/videos/CartPole-v1__cartpole__0__1709195828/rl-video-episode-27.mp4
Moviepy - Done !
Moviepy - video ready /Users/nicolasvila/workplace/uni/tfg_v2/tests/videos/CartPole-v1__cartpole__0__1709195828/rl-video-episode-27.mp4
/Users/nicolasvila/workplace/uni/tfg_v2/tests/qreps_val/qreps/memory/replay_buffer.py:47: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:264.)
  obs_tm1 = torch.tensor(obs_tm1).float()
[2024-02-29 09:37:22,867]: Iteration 0 done, Reward 0.15
[2024-02-29 09:37:23,147]: Iteration 1 done, Reward 0.12
[2024-02-29 09:37:23,476]: Iteration 2 done, Reward 0.11
[2024-02-29 09:37:23,837]: Iteration 3 done, Reward 0.14
[2024-02-29 09:37:24,110]: Iteration 4 done, Reward 0.11
Moviepy - Building video /Users/nicolasvila/workplace/uni/tfg_v2/tests/videos/CartPole-v1__cartpole__0__1709195828/rl-video-episode-64.mp4.
Moviepy - Writing video /Users/nicolasvila/workplace/uni/tfg_v2/tests/videos/CartPole-v1__cartpole__0__1709195828/rl-video-episode-64.mp4
Moviepy - Done !
Moviepy - video ready /Users/nicolasvila/workplace/uni/tfg_v2/tests/videos/CartPole-v1__cartpole__0__1709195828/rl-video-episode-64.mp4
[2024-02-29 09:37:24,384]: Iteration 5 done, Reward 0.11
Traceback (most recent call last):
  File "/Users/nicolasvila/workplace/uni/tfg_v2/tests/qreps_val/experiments/cartpole.py", line 121, in <module>
    train(qreps_config)
  File "/Users/nicolasvila/workplace/uni/tfg_v2/tests/qreps_val/experiments/cartpole.py", line 117, in train
    trainer.train(num_iterations=10000, max_steps=200, number_rollouts=10)
  File "/Users/nicolasvila/workplace/uni/tfg_v2/tests/qreps_val/qreps/utilities/trainer.py", line 62, in train
    self.algo.update_policy(self.iter)
  File "/Users/nicolasvila/workplace/uni/tfg_v2/tests/qreps_val/qreps/algorithms/qreps.py", line 77, in update_policy
    self.optimize_loss(self.dual, optimizer=self.theta_opt)
  File "/Users/nicolasvila/workplace/uni/tfg_v2/tests/qreps_val/qreps/algorithms/abstract_algorithm.py", line 166, in optimize_loss
    optimizer.step(closure)
  File "/Users/nicolasvila/miniconda3/lib/python3.11/site-packages/torch/optim/optimizer.py", line 373, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nicolasvila/miniconda3/lib/python3.11/site-packages/torch/optim/optimizer.py", line 76, in _use_grad
    ret = func(self, *args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nicolasvila/miniconda3/lib/python3.11/site-packages/torch/optim/adam.py", line 143, in step
    loss = closure()
           ^^^^^^^^^
  File "/Users/nicolasvila/workplace/uni/tfg_v2/tests/qreps_val/qreps/algorithms/abstract_algorithm.py", line 161, in closure
    loss = loss_fn(observations, next_observations, rewards, actions)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nicolasvila/workplace/uni/tfg_v2/tests/qreps_val/qreps/algorithms/qreps.py", line 52, in dual
    return empirical_logistic_bellman(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nicolasvila/workplace/uni/tfg_v2/tests/qreps_val/qreps/utilities/elbe.py", line 30, in empirical_logistic_bellman
    ) + torch.mean((1 - discount) * v_func(features), 0)
                                    ^^^^^^^^^^^^^^^^
  File "/Users/nicolasvila/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nicolasvila/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nicolasvila/workplace/uni/tfg_v2/tests/qreps_val/qreps/valuefunctions/integrated_q_function.py", line 17, in forward
    q_values = self.q_func.forward_state(obs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nicolasvila/workplace/uni/tfg_v2/tests/qreps_val/qreps/valuefunctions/q_function.py", line 43, in forward_state
    return self.model(input)
           ^^^^^^^^^^^^^^^^^
  File "/Users/nicolasvila/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nicolasvila/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nicolasvila/miniconda3/lib/python3.11/site-packages/torch/nn/modules/container.py", line 215, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/Users/nicolasvila/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nicolasvila/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nicolasvila/miniconda3/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt