{".out_test_1/global_step": 1000, "_timestamp": 1708559534.235434, ".out_test_1/time/steps": 1000.0, "global_step": 1000, ".out_test_1/time/epochs": 0.0, ".out_test_1/time/steps_per_second": 11.609514236450195, ".out_test_1/time/dataset": 0.0004780292510986328, ".out_test_1/time/preprocess": 1.1920928955078125e-05, ".out_test_1/time/train_step": 0.08895397186279297, ".out_test_1/train/env_steps": 988.0, "_runtime": 45.93747305870056, "_step": 502, "Losses/Q Loss": -22.74538803100586, ".out_test_1/train/q_loss": -22.63762092590332, ".out_test_1/train/target_q": -0.07971560209989548, ".out_test_1/train/alpha_loss": 0.9700360298156738, ".out_test_1/train/actor_loss": -0.29813259840011597, ".out_test_1/train/entropy": 3.9447290897369385, ".out_test_1/train/alpha": 0.09753280878067017, "_wandb": {"runtime": 46}, ".out_test_1/train/reward": 4.09133768081665, ".out_test_1/train/length": 1000.0, ".out_test_1/train/num_ep": 1.0}