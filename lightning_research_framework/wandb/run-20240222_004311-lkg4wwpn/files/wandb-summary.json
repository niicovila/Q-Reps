{".out_test_1/global_step": 500, "_timestamp": 1708559496.31282, ".out_test_1/time/steps": 500.0, "global_step": 3100, ".out_test_1/time/epochs": 0.0, ".out_test_1/time/steps_per_second": 329.71600341796875, ".out_test_1/time/dataset": 0.0001010894775390625, ".out_test_1/time/preprocess": 3.814697265625e-06, ".out_test_1/time/train_step": 8.392333984375e-05, ".out_test_1/train/env_steps": 488.0, "_runtime": 504.59203600883484, "_step": 5163, "Losses/Q Loss": -23.745914459228516, ".out_test_1/train/q_loss": -14.69150161743164, ".out_test_1/train/target_q": -0.09822434186935425, ".out_test_1/train/alpha_loss": 0.8867744207382202, ".out_test_1/train/actor_loss": -0.3499414622783661, ".out_test_1/train/entropy": 4.077917098999023, ".out_test_1/train/alpha": 0.08798342198133469, ".out_test_1/train/reward": 4.931243896484375, ".out_test_1/train/length": 1000.0, ".out_test_1/train/num_ep": 3.0, ".out_test_1/eval/reward": 0.27501538395881653, ".out_test_1/eval/stddev": 0.18226400017738342, ".out_test_1/eval/length": 1000.0, ".out_test_1/eval/discount": 1000.0, ".out_test_1/eval/early_termination": 0.0, "_wandb": {"runtime": 499}}