{".out_test_1/global_step": 125000, "_timestamp": 1708574351.4126232, ".out_test_1/time/steps": 125000.0, "global_step": 125000, ".out_test_1/time/epochs": 0.0, ".out_test_1/time/steps_per_second": 8.407114028930664, ".out_test_1/time/dataset": 0.0005202293395996094, ".out_test_1/time/preprocess": 1.5974044799804688e-05, ".out_test_1/time/train_step": 0.1321871280670166, ".out_test_1/train/env_steps": 124988.0, "_runtime": 14773.810482263565, "_step": 127962, "Losses/Q Loss": -16.526309967041016, ".out_test_1/train/q_loss": -16.578035354614258, ".out_test_1/train/target_q": 0.6953259706497192, ".out_test_1/train/alpha_loss": -5.984623567201197e-05, ".out_test_1/train/actor_loss": -0.7350661158561707, ".out_test_1/train/entropy": -6.030946254730225, ".out_test_1/train/alpha": 0.0019338795682415366, ".out_test_1/train/reward": 143.5082550048828, ".out_test_1/train/length": 1000.0, ".out_test_1/train/num_ep": 125.0, ".out_test_1/eval/reward": 168.99078369140625, ".out_test_1/eval/stddev": 26.185916900634766, ".out_test_1/eval/length": 1000.0, ".out_test_1/eval/discount": 1000.0, ".out_test_1/eval/early_termination": 0.0, "_wandb": {"runtime": 14775}}