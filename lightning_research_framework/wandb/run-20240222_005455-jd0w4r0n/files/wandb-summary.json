{".out_test_2/global_step": 17675, "_timestamp": 1708576452.205207, ".out_test_2/time/steps": 17675.0, "global_step": 123925, ".out_test_2/time/epochs": 0.0, ".out_test_2/time/steps_per_second": 14.148024559020996, ".out_test_2/time/dataset": 0.0006821155548095703, ".out_test_2/time/preprocess": 1.2874603271484375e-05, ".out_test_2/time/train_step": 0.1332852840423584, ".out_test_2/train/env_steps": 17663.0, "_runtime": 16756.82196521759, "_step": 144718, ".out_test_2/train/q_loss": -19.98174285888672, ".out_test_2/train/target_q": 0.12258697301149368, ".out_test_2/train/alpha_loss": 0.4457815885543823, ".out_test_2/train/actor_loss": -0.2993401288986206, ".out_test_2/train/entropy": 3.861609697341919, ".out_test_2/train/alpha": 0.045199666172266006, "Losses/Q Loss": -20.218334197998047, ".out_test_2/train/reward": 33.61511993408203, ".out_test_2/train/length": 1000.0, ".out_test_2/train/num_ep": 17.0, ".out_test_2/eval/reward": 47.43263626098633, ".out_test_2/eval/stddev": 0.9067254662513733, ".out_test_2/eval/length": 1000.0, ".out_test_2/eval/discount": 1000.0, ".out_test_2/eval/early_termination": 0.0, "_wandb": {"runtime": 16750}}