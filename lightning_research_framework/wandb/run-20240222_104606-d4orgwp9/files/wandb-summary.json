{".out_test_1/global_step": 3850, "_timestamp": 1708595781.831947, ".out_test_1/time/steps": 3850.0, "global_step": 3850, ".out_test_1/time/epochs": 0.0, ".out_test_1/time/steps_per_second": 5.667148113250732, ".out_test_1/time/dataset": 0.0007522106170654297, ".out_test_1/time/preprocess": 2.47955322265625e-05, ".out_test_1/time/train_step": 0.2766242027282715, ".out_test_1/train/env_steps": 3838.0, "_runtime": 614.8292281627655, "_step": 3712, ".out_test_1/train/q_loss": 0.19993659853935242, ".out_test_1/train/target_q": Infinity, ".out_test_1/train/alpha_loss": 0.8263474702835083, ".out_test_1/train/actor_loss": -3.2539663314819336, ".out_test_1/train/entropy": 3.8388290405273438, ".out_test_1/train/alpha": 0.0839805155992508, "Losses/Q Loss": 0.19990211725234985, ".out_test_1/train/reward": 2.963063955307007, ".out_test_1/train/length": 1000.0, ".out_test_1/train/num_ep": 3.0, "_wandb": {"runtime": 616}}