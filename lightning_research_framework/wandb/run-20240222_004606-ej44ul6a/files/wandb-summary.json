{".out_test_1/global_step": 3100, "_timestamp": 1708559459.767808, ".out_test_1/time/steps": 3100.0, "global_step": 3100, ".out_test_1/time/epochs": 0.0, ".out_test_1/time/steps_per_second": 9.127741813659668, ".out_test_1/time/dataset": 0.00039386749267578125, ".out_test_1/time/preprocess": 1.3828277587890625e-05, ".out_test_1/time/train_step": 0.12704110145568848, ".out_test_1/train/env_steps": 3088.0, "_runtime": 293.43856501579285, "_step": 2682, ".out_test_1/train/q_loss": -24.02431297302246, ".out_test_1/train/target_q": -0.0019144833786413074, ".out_test_1/train/alpha_loss": 0.8867744207382202, ".out_test_1/train/actor_loss": -0.3499414622783661, ".out_test_1/train/entropy": 4.077917098999023, ".out_test_1/train/alpha": 0.08798342198133469, "Losses/Q Loss": -23.745914459228516, ".out_test_1/train/reward": 4.931243896484375, ".out_test_1/train/length": 1000.0, ".out_test_1/train/num_ep": 3.0, ".out_test_1/eval/reward": 0.27501538395881653, ".out_test_1/eval/stddev": 0.18226400017738342, ".out_test_1/eval/length": 1000.0, ".out_test_1/eval/discount": 1000.0, ".out_test_1/eval/early_termination": 0.0, "_wandb": {"runtime": 293}}