/Users/nicolasvila/miniconda3/envs/cleanrl/lib/python3.9/site-packages/wandb/sdk/lib/import_hooks.py:243: DeprecationWarning: Deprecated since Python 3.4. Use importlib.util.find_spec() instead.
  loader = importlib.find_loader(fullname, path)
/Users/nicolasvila/miniconda3/envs/cleanrl/lib/python3.9/site-packages/stable_baselines3/common/buffers.py:229: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 56.46GB > 1.48GB
  warnings.warn(
global_step=139, episodic_return=[1.]
global_step=324, episodic_return=[2.]
global_step=435, episodic_return=[0.]
global_step=673, episodic_return=[3.]
global_step=935, episodic_return=[3.]
global_step=1141, episodic_return=[2.]
global_step=1352, episodic_return=[2.]
global_step=1495, episodic_return=[1.]
global_step=1608, episodic_return=[0.]
global_step=1767, episodic_return=[1.]
global_step=1882, episodic_return=[0.]
global_step=1995, episodic_return=[0.]
global_step=2201, episodic_return=[2.]
global_step=2312, episodic_return=[0.]
global_step=2471, episodic_return=[1.]
global_step=2678, episodic_return=[2.]
global_step=2819, episodic_return=[1.]
global_step=2978, episodic_return=[1.]
global_step=3091, episodic_return=[0.]
global_step=3206, episodic_return=[0.]
global_step=3392, episodic_return=[2.]
global_step=3503, episodic_return=[0.]
global_step=3677, episodic_return=[2.]
global_step=3792, episodic_return=[0.]
global_step=3951, episodic_return=[1.]
global_step=4064, episodic_return=[0.]
global_step=4222, episodic_return=[1.]
global_step=4335, episodic_return=[0.]
global_step=4556, episodic_return=[3.]
global_step=4671, episodic_return=[0.]
global_step=4924, episodic_return=[4.]
global_step=5037, episodic_return=[0.]
global_step=5198, episodic_return=[1.]
global_step=5357, episodic_return=[1.]
global_step=5468, episodic_return=[0.]
global_step=5611, episodic_return=[1.]
global_step=5724, episodic_return=[0.]
global_step=5965, episodic_return=[4.]
global_step=6124, episodic_return=[1.]
global_step=6314, episodic_return=[2.]
global_step=6427, episodic_return=[0.]
global_step=6542, episodic_return=[0.]
global_step=6655, episodic_return=[0.]
global_step=6798, episodic_return=[1.]
global_step=7175, episodic_return=[7.]
global_step=7431, episodic_return=[3.]
global_step=7544, episodic_return=[0.]
global_step=7655, episodic_return=[0.]
global_step=7768, episodic_return=[0.]
global_step=7976, episodic_return=[2.]
global_step=8237, episodic_return=[3.]
global_step=8394, episodic_return=[1.]
global_step=8663, episodic_return=[4.]
global_step=9034, episodic_return=[7.]
global_step=9175, episodic_return=[1.]
global_step=9288, episodic_return=[0.]
global_step=9401, episodic_return=[0.]
global_step=9657, episodic_return=[3.]
global_step=9816, episodic_return=[1.]
global_step=9957, episodic_return=[1.]
global_step=10191, episodic_return=[3.]
global_step=10306, episodic_return=[0.]
global_step=10417, episodic_return=[0.]
global_step=10783, episodic_return=[6.]
global_step=10896, episodic_return=[0.]
global_step=11072, episodic_return=[2.]
global_step=11229, episodic_return=[1.]
global_step=11404, episodic_return=[2.]
global_step=11519, episodic_return=[0.]
global_step=11678, episodic_return=[1.]
global_step=11791, episodic_return=[0.]
global_step=11906, episodic_return=[0.]
global_step=12090, episodic_return=[2.]
global_step=12233, episodic_return=[1.]
global_step=12422, episodic_return=[2.]
global_step=12533, episodic_return=[0.]
global_step=12717, episodic_return=[2.]
global_step=12876, episodic_return=[1.]
global_step=12989, episodic_return=[0.]
global_step=13195, episodic_return=[2.]
global_step=13401, episodic_return=[2.]
global_step=13544, episodic_return=[1.]
global_step=13657, episodic_return=[0.]
global_step=13772, episodic_return=[0.]
global_step=13887, episodic_return=[0.]
global_step=14123, episodic_return=[3.]
global_step=14236, episodic_return=[0.]
global_step=14430, episodic_return=[2.]
global_step=14642, episodic_return=[3.]
global_step=14878, episodic_return=[3.]
global_step=15112, episodic_return=[3.]
global_step=15302, episodic_return=[2.]
global_step=15415, episodic_return=[0.]
global_step=15530, episodic_return=[0.]
global_step=15643, episodic_return=[0.]
global_step=15802, episodic_return=[1.]
global_step=16036, episodic_return=[3.]
global_step=16363, episodic_return=[5.]
global_step=16476, episodic_return=[0.]
global_step=16637, episodic_return=[1.]
global_step=16750, episodic_return=[0.]
global_step=16861, episodic_return=[0.]
global_step=16974, episodic_return=[0.]
global_step=17089, episodic_return=[0.]
global_step=17204, episodic_return=[0.]
global_step=17315, episodic_return=[0.]
global_step=17526, episodic_return=[2.]
global_step=17665, episodic_return=[1.]
global_step=17902, episodic_return=[3.]
global_step=18063, episodic_return=[1.]
global_step=18271, episodic_return=[2.]
global_step=18463, episodic_return=[2.]
global_step=18606, episodic_return=[1.]
global_step=18749, episodic_return=[1.]
global_step=18864, episodic_return=[0.]
global_step=18979, episodic_return=[0.]
global_step=19266, episodic_return=[4.]
global_step=19379, episodic_return=[0.]
/Users/nicolasvila/miniconda3/envs/cleanrl/lib/python3.9/site-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
global_step=19540, episodic_return=[1.]
global_step=19703, episodic_return=[1.]
global_step=19816, episodic_return=[0.]
global_step=19973, episodic_return=[1.]
SPS: 719
SPS: 509
global_step=20205, episodic_return=[3.]
SPS: 395
SPS: 323
global_step=20411, episodic_return=[2.]
SPS: 274
SPS: 238
SPS: 210
global_step=20740, episodic_return=[5.]
SPS: 189
SPS: 171
global_step=20972, episodic_return=[3.]
SPS: 156
SPS: 143
global_step=21158, episodic_return=[2.]
SPS: 133
global_step=21273, episodic_return=[0.]
SPS: 124
global_step=21386, episodic_return=[0.]
SPS: 116
SPS: 110
global_step=21570, episodic_return=[2.]
SPS: 103
SPS: 98
SPS: 94
global_step=21802, episodic_return=[3.]
SPS: 89
global_step=21990, episodic_return=[2.]
SPS: 86
SPS: 82
global_step=22101, episodic_return=[0.]
SPS: 79
global_step=22212, episodic_return=[0.]
SPS: 76
SPS: 73
global_step=22495, episodic_return=[4.]
SPS: 71
SPS: 68
SPS: 66
global_step=22729, episodic_return=[3.]
SPS: 64
SPS: 63
SPS: 61
global_step=23012, episodic_return=[4.]
SPS: 59
SPS: 58
SPS: 56
SPS: 55
global_step=23402, episodic_return=[9.]
SPS: 53
global_step=23517, episodic_return=[0.]
SPS: 52
SPS: 51
global_step=23749, episodic_return=[3.]
SPS: 50
SPS: 48
global_step=23981, episodic_return=[3.]
SPS: 47
SPS: 46
SPS: 45
global_step=24215, episodic_return=[3.]
SPS: 45
global_step=24399, episodic_return=[2.]
SPS: 44
SPS: 43
SPS: 42
SPS: 42
global_step=24735, episodic_return=[5.]
SPS: 41
SPS: 40
global_step=24919, episodic_return=[2.]
Traceback (most recent call last):
  File "/Users/nicolasvila/workplace/uni/tfg/tests/cleanrl/sac/sac_atari.py", line 251, in <module>
    actions, _, _ = actor.get_action(torch.Tensor(obs).to(device))
  File "/Users/nicolasvila/workplace/uni/tfg/tests/cleanrl/sac/sac_atari.py", line 165, in get_action
    policy_dist = Categorical(logits=logits)
  File "/Users/nicolasvila/miniconda3/envs/cleanrl/lib/python3.9/site-packages/torch/distributions/categorical.py", line 64, in __init__
    super(Categorical, self).__init__(batch_shape, validate_args=validate_args)
  File "/Users/nicolasvila/miniconda3/envs/cleanrl/lib/python3.9/site-packages/torch/distributions/distribution.py", line 55, in __init__
    raise ValueError(
ValueError: Expected parameter logits (Tensor of shape (1, 4)) of distribution Categorical(logits: torch.Size([1, 4])) to satisfy the constraint IndependentConstraint(Real(), 1), but found invalid values:
tensor([[nan, nan, nan, nan]], grad_fn=<SubBackward0>)