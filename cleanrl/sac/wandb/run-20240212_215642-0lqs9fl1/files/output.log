/Users/nicolasvila/miniconda3/envs/cleanrl/lib/python3.9/site-packages/wandb/sdk/lib/import_hooks.py:243: DeprecationWarning: Deprecated since Python 3.4. Use importlib.util.find_spec() instead.
  loader = importlib.find_loader(fullname, path)
/Users/nicolasvila/miniconda3/envs/cleanrl/lib/python3.9/site-packages/stable_baselines3/common/buffers.py:229: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 56.46GB > 1.31GB
  warnings.warn(
global_step=139, episodic_return=[1.]
global_step=324, episodic_return=[2.]
global_step=435, episodic_return=[0.]
global_step=673, episodic_return=[3.]
global_step=935, episodic_return=[3.]
global_step=1141, episodic_return=[2.]
global_step=1352, episodic_return=[2.]
global_step=1495, episodic_return=[1.]
global_step=1608, episodic_return=[0.]
global_step=1767, episodic_return=[1.]
global_step=1882, episodic_return=[0.]
global_step=1995, episodic_return=[0.]
global_step=2201, episodic_return=[2.]
global_step=2312, episodic_return=[0.]
global_step=2471, episodic_return=[1.]
global_step=2678, episodic_return=[2.]
global_step=2819, episodic_return=[1.]
global_step=2978, episodic_return=[1.]
global_step=3091, episodic_return=[0.]
global_step=3206, episodic_return=[0.]
global_step=3392, episodic_return=[2.]
global_step=3503, episodic_return=[0.]
global_step=3677, episodic_return=[2.]
global_step=3792, episodic_return=[0.]
global_step=3951, episodic_return=[1.]
global_step=4064, episodic_return=[0.]
global_step=4222, episodic_return=[1.]
global_step=4335, episodic_return=[0.]
global_step=4556, episodic_return=[3.]
global_step=4671, episodic_return=[0.]
global_step=4924, episodic_return=[4.]
global_step=5037, episodic_return=[0.]
global_step=5198, episodic_return=[1.]
global_step=5357, episodic_return=[1.]
global_step=5468, episodic_return=[0.]
global_step=5611, episodic_return=[1.]
global_step=5724, episodic_return=[0.]
global_step=5965, episodic_return=[4.]
global_step=6124, episodic_return=[1.]
global_step=6314, episodic_return=[2.]
global_step=6427, episodic_return=[0.]
global_step=6542, episodic_return=[0.]
global_step=6655, episodic_return=[0.]
global_step=6798, episodic_return=[1.]
global_step=7175, episodic_return=[7.]
global_step=7431, episodic_return=[3.]
global_step=7544, episodic_return=[0.]
global_step=7655, episodic_return=[0.]
global_step=7768, episodic_return=[0.]
global_step=7976, episodic_return=[2.]
global_step=8237, episodic_return=[3.]
global_step=8394, episodic_return=[1.]
global_step=8663, episodic_return=[4.]
global_step=9034, episodic_return=[7.]
global_step=9175, episodic_return=[1.]
global_step=9288, episodic_return=[0.]
global_step=9401, episodic_return=[0.]
global_step=9657, episodic_return=[3.]
global_step=9816, episodic_return=[1.]
global_step=9957, episodic_return=[1.]
global_step=10191, episodic_return=[3.]
global_step=10306, episodic_return=[0.]
global_step=10417, episodic_return=[0.]
global_step=10783, episodic_return=[6.]
global_step=10896, episodic_return=[0.]
global_step=11072, episodic_return=[2.]
global_step=11229, episodic_return=[1.]
global_step=11404, episodic_return=[2.]
global_step=11519, episodic_return=[0.]
global_step=11678, episodic_return=[1.]
global_step=11791, episodic_return=[0.]
global_step=11906, episodic_return=[0.]
global_step=12090, episodic_return=[2.]
global_step=12233, episodic_return=[1.]
global_step=12422, episodic_return=[2.]
global_step=12533, episodic_return=[0.]
global_step=12717, episodic_return=[2.]
global_step=12876, episodic_return=[1.]
global_step=12989, episodic_return=[0.]
global_step=13195, episodic_return=[2.]
global_step=13401, episodic_return=[2.]
global_step=13544, episodic_return=[1.]
global_step=13657, episodic_return=[0.]
global_step=13772, episodic_return=[0.]
global_step=13887, episodic_return=[0.]
global_step=14123, episodic_return=[3.]
global_step=14236, episodic_return=[0.]
global_step=14430, episodic_return=[2.]
global_step=14642, episodic_return=[3.]
global_step=14878, episodic_return=[3.]
global_step=15112, episodic_return=[3.]
global_step=15302, episodic_return=[2.]
global_step=15415, episodic_return=[0.]
global_step=15530, episodic_return=[0.]
global_step=15643, episodic_return=[0.]
global_step=15802, episodic_return=[1.]
global_step=16036, episodic_return=[3.]
global_step=16363, episodic_return=[5.]
global_step=16476, episodic_return=[0.]
global_step=16637, episodic_return=[1.]
global_step=16750, episodic_return=[0.]
global_step=16861, episodic_return=[0.]
global_step=16974, episodic_return=[0.]
global_step=17089, episodic_return=[0.]
global_step=17204, episodic_return=[0.]
global_step=17315, episodic_return=[0.]
global_step=17526, episodic_return=[2.]
global_step=17665, episodic_return=[1.]
global_step=17902, episodic_return=[3.]
global_step=18063, episodic_return=[1.]
global_step=18271, episodic_return=[2.]
global_step=18463, episodic_return=[2.]
global_step=18606, episodic_return=[1.]
global_step=18749, episodic_return=[1.]
global_step=18864, episodic_return=[0.]
global_step=18979, episodic_return=[0.]
global_step=19266, episodic_return=[4.]
global_step=19379, episodic_return=[0.]
global_step=19540, episodic_return=[1.]
global_step=19703, episodic_return=[1.]
global_step=19816, episodic_return=[0.]
global_step=19973, episodic_return=[1.]
/Users/nicolasvila/miniconda3/envs/cleanrl/lib/python3.9/site-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
SPS: 671
SPS: 485
SPS: 379
global_step=20363, episodic_return=[9.]
SPS: 312
SPS: 265
SPS: 230
SPS: 205
global_step=20753, episodic_return=[9.]
SPS: 184
SPS: 167
SPS: 154
global_step=21089, episodic_return=[5.]
SPS: 142
SPS: 132
global_step=21204, episodic_return=[0.]
SPS: 124
global_step=21319, episodic_return=[0.]
SPS: 116
global_step=21434, episodic_return=[0.]
SPS: 109
global_step=21549, episodic_return=[0.]
SPS: 104
global_step=21664, episodic_return=[0.]
SPS: 98
global_step=21779, episodic_return=[0.]
SPS: 94
global_step=21894, episodic_return=[0.]
SPS: 90
SPS: 86
global_step=22009, episodic_return=[0.]
SPS: 82
global_step=22124, episodic_return=[0.]
SPS: 79
SPS: 76
SPS: 74
SPS: 71
global_step=22514, episodic_return=[9.]
SPS: 69
global_step=22629, episodic_return=[0.]
SPS: 67
SPS: 65
SPS: 63
SPS: 61
global_step=23019, episodic_return=[9.]
SPS: 60
SPS: 58
SPS: 57
SPS: 55
global_step=23409, episodic_return=[9.]
SPS: 54
global_step=23524, episodic_return=[0.]
SPS: 53
SPS: 52
SPS: 51
SPS: 50
global_step=23914, episodic_return=[9.]
SPS: 49
SPS: 48
SPS: 47
SPS: 46
global_step=24304, episodic_return=[9.]
SPS: 45
global_step=24419, episodic_return=[0.]
SPS: 44
global_step=24534, episodic_return=[0.]
SPS: 43
SPS: 43
SPS: 42
SPS: 41
global_step=24924, episodic_return=[9.]
SPS: 41
global_step=25039, episodic_return=[0.]
SPS: 40
global_step=25154, episodic_return=[0.]
SPS: 39
global_step=25269, episodic_return=[0.]
SPS: 39
global_step=25384, episodic_return=[0.]
SPS: 38
SPS: 38
SPS: 37
SPS: 37
global_step=25774, episodic_return=[9.]
SPS: 36
global_step=25889, episodic_return=[0.]
SPS: 36
SPS: 35
global_step=26004, episodic_return=[0.]
SPS: 35
SPS: 34
SPS: 34
global_step=26394, episodic_return=[9.]
SPS: 34
SPS: 33
global_step=26509, episodic_return=[0.]
SPS: 33
global_step=26624, episodic_return=[0.]
SPS: 33
global_step=26739, episodic_return=[0.]
SPS: 32
global_step=26854, episodic_return=[0.]
SPS: 32
global_step=26969, episodic_return=[0.]
SPS: 32
global_step=27084, episodic_return=[0.]
SPS: 31
global_step=27199, episodic_return=[0.]
SPS: 31
SPS: 31
global_step=27314, episodic_return=[0.]
SPS: 30
global_step=27429, episodic_return=[0.]
SPS: 30
global_step=27544, episodic_return=[0.]
SPS: 30
global_step=27659, episodic_return=[0.]
SPS: 29
global_step=27774, episodic_return=[0.]
SPS: 29
global_step=27889, episodic_return=[0.]
SPS: 29
SPS: 29
global_step=28004, episodic_return=[0.]
SPS: 28
global_step=28119, episodic_return=[0.]
SPS: 28
global_step=28234, episodic_return=[0.]
SPS: 28
global_step=28349, episodic_return=[0.]
SPS: 28
SPS: 27
SPS: 27
SPS: 27
global_step=28739, episodic_return=[9.]
SPS: 27
SPS: 27
SPS: 26
SPS: 26
global_step=29129, episodic_return=[9.]
SPS: 26
global_step=29244, episodic_return=[0.]
SPS: 26
global_step=29359, episodic_return=[0.]
SPS: 26
global_step=29474, episodic_return=[0.]
SPS: 25
global_step=29589, episodic_return=[0.]
SPS: 25
SPS: 25
SPS: 25
SPS: 25
global_step=29979, episodic_return=[9.]
SPS: 25
global_step=30094, episodic_return=[0.]
SPS: 24
SPS: 24
global_step=30209, episodic_return=[0.]
SPS: 24
SPS: 24
SPS: 24
global_step=30599, episodic_return=[9.]
SPS: 24
SPS: 23
global_step=30714, episodic_return=[0.]
SPS: 23
global_step=30829, episodic_return=[0.]
SPS: 23
SPS: 23
SPS: 23
SPS: 23
global_step=31219, episodic_return=[9.]
SPS: 23
global_step=31334, episodic_return=[0.]
SPS: 23
SPS: 22
Traceback (most recent call last):
  File "/Users/nicolasvila/workplace/uni/tfg/tests/cleanrl/sac/sac_atari.py", line 297, in <module>
    qf1_values = qf1(data.observations)
  File "/Users/nicolasvila/miniconda3/envs/cleanrl/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/Users/nicolasvila/workplace/uni/tfg/tests/cleanrl/sac/sac_atari.py", line 131, in forward
    x = F.relu(self.conv(x / 255.0))
  File "/Users/nicolasvila/miniconda3/envs/cleanrl/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/Users/nicolasvila/miniconda3/envs/cleanrl/lib/python3.9/site-packages/torch/nn/modules/container.py", line 139, in forward
    input = module(input)
  File "/Users/nicolasvila/miniconda3/envs/cleanrl/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/Users/nicolasvila/miniconda3/envs/cleanrl/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/Users/nicolasvila/miniconda3/envs/cleanrl/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
KeyboardInterrupt
SPS: 22