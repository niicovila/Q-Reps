[34m[1mwandb[39m[22m: [33mWARNING[39m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
/Users/nicolasvila/miniconda3/lib/python3.11/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/Users/nicolasvila/workplace/uni/QREPS_ORIGINAL/tests/qreps_val/qreps/memory/replay_buffer.py:47: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:264.)
  obs_tm1 = torch.tensor(obs_tm1).float()
[2024-02-13 13:57:17,837]: Iteration 0 done, Reward 1.13
Moviepy - Building video /Users/nicolasvila/workplace/uni/QREPS_ORIGINAL/tests/qreps_val/videos/CartPole-v1__cartpole__14__1707829027/rl-video-episode-0.mp4.
Moviepy - Writing video /Users/nicolasvila/workplace/uni/QREPS_ORIGINAL/tests/qreps_val/videos/CartPole-v1__cartpole__14__1707829027/rl-video-episode-0.mp4
Moviepy - Done !
Moviepy - video ready /Users/nicolasvila/workplace/uni/QREPS_ORIGINAL/tests/qreps_val/videos/CartPole-v1__cartpole__14__1707829027/rl-video-episode-0.mp4
Moviepy - Building video /Users/nicolasvila/workplace/uni/QREPS_ORIGINAL/tests/qreps_val/videos/CartPole-v1__cartpole__14__1707829027/rl-video-episode-1.mp4.
Moviepy - Writing video /Users/nicolasvila/workplace/uni/QREPS_ORIGINAL/tests/qreps_val/videos/CartPole-v1__cartpole__14__1707829027/rl-video-episode-1.mp4
Moviepy - Done !
Moviepy - video ready /Users/nicolasvila/workplace/uni/QREPS_ORIGINAL/tests/qreps_val/videos/CartPole-v1__cartpole__14__1707829027/rl-video-episode-1.mp4
Moviepy - Building video /Users/nicolasvila/workplace/uni/QREPS_ORIGINAL/tests/qreps_val/videos/CartPole-v1__cartpole__14__1707829027/rl-video-episode-8.mp4.
Moviepy - Writing video /Users/nicolasvila/workplace/uni/QREPS_ORIGINAL/tests/qreps_val/videos/CartPole-v1__cartpole__14__1707829027/rl-video-episode-8.mp4
Moviepy - Done !
Moviepy - video ready /Users/nicolasvila/workplace/uni/QREPS_ORIGINAL/tests/qreps_val/videos/CartPole-v1__cartpole__14__1707829027/rl-video-episode-8.mp4
Moviepy - Building video /Users/nicolasvila/workplace/uni/QREPS_ORIGINAL/tests/qreps_val/videos/CartPole-v1__cartpole__14__1707829027/rl-video-episode-27.mp4.
Moviepy - Writing video /Users/nicolasvila/workplace/uni/QREPS_ORIGINAL/tests/qreps_val/videos/CartPole-v1__cartpole__14__1707829027/rl-video-episode-27.mp4
Moviepy - Done !
Moviepy - video ready /Users/nicolasvila/workplace/uni/QREPS_ORIGINAL/tests/qreps_val/videos/CartPole-v1__cartpole__14__1707829027/rl-video-episode-27.mp4
Moviepy - Building video /Users/nicolasvila/workplace/uni/QREPS_ORIGINAL/tests/qreps_val/videos/CartPole-v1__cartpole__14__1707829027/rl-video-episode-64.mp4.
Moviepy - Writing video /Users/nicolasvila/workplace/uni/QREPS_ORIGINAL/tests/qreps_val/videos/CartPole-v1__cartpole__14__1707829027/rl-video-episode-64.mp4
Moviepy - Done !
Moviepy - video ready /Users/nicolasvila/workplace/uni/QREPS_ORIGINAL/tests/qreps_val/videos/CartPole-v1__cartpole__14__1707829027/rl-video-episode-64.mp4
[2024-02-13 13:57:32,385]: Iteration 1 done, Reward 24.59
t:   0%|                                                                                          | 0/67 [00:00<?, ?it/s, now=None]
Moviepy - Building video /Users/nicolasvila/workplace/uni/QREPS_ORIGINAL/tests/qreps_val/videos/CartPole-v1__cartpole__14__1707829027/rl-video-episode-125.mp4.

[2024-02-13 13:57:34,328]: Iteration 2 done, Reward 2.93
Moviepy - Done !
Moviepy - video ready /Users/nicolasvila/workplace/uni/QREPS_ORIGINAL/tests/qreps_val/videos/CartPole-v1__cartpole__14__1707829027/rl-video-episode-125.mp4
Moviepy - Building video /Users/nicolasvila/workplace/uni/QREPS_ORIGINAL/tests/qreps_val/videos/CartPole-v1__cartpole__14__1707829027/rl-video-episode-216.mp4.
Moviepy - Writing video /Users/nicolasvila/workplace/uni/QREPS_ORIGINAL/tests/qreps_val/videos/CartPole-v1__cartpole__14__1707829027/rl-video-episode-216.mp4
Moviepy - Done !
Moviepy - video ready /Users/nicolasvila/workplace/uni/QREPS_ORIGINAL/tests/qreps_val/videos/CartPole-v1__cartpole__14__1707829027/rl-video-episode-216.mp4
[2024-02-13 13:57:47,386]: Iteration 3 done, Reward 23.43
[2024-02-13 13:57:58,529]: Iteration 4 done, Reward 15.20
[2024-02-13 13:58:08,500]: Iteration 5 done, Reward 17.32
t:  66%|███████████████████████████████████████████████████▍                          | 331/502 [00:00<00:00, 723.70it/s, now=None]
Moviepy - Building video /Users/nicolasvila/workplace/uni/QREPS_ORIGINAL/tests/qreps_val/videos/CartPole-v1__cartpole__14__1707829027/rl-video-episode-343.mp4.

Moviepy - Writing video /Users/nicolasvila/workplace/uni/QREPS_ORIGINAL/tests/qreps_val/videos/CartPole-v1__cartpole__14__1707829027/rl-video-episode-343.mp4
Moviepy - Done !
Moviepy - video ready /Users/nicolasvila/workplace/uni/QREPS_ORIGINAL/tests/qreps_val/videos/CartPole-v1__cartpole__14__1707829027/rl-video-episode-343.mp4
[2024-02-13 13:58:19,732]: Iteration 6 done, Reward 17.85
[2024-02-13 13:58:29,084]: Iteration 7 done, Reward 18.03
Moviepy - Building video /Users/nicolasvila/workplace/uni/QREPS_ORIGINAL/tests/qreps_val/videos/CartPole-v1__cartpole__14__1707829027/rl-video-episode-512.mp4.
Moviepy - Writing video /Users/nicolasvila/workplace/uni/QREPS_ORIGINAL/tests/qreps_val/videos/CartPole-v1__cartpole__14__1707829027/rl-video-episode-512.mp4
Moviepy - Done !
Moviepy - video ready /Users/nicolasvila/workplace/uni/QREPS_ORIGINAL/tests/qreps_val/videos/CartPole-v1__cartpole__14__1707829027/rl-video-episode-512.mp4
[2024-02-13 13:58:29,890]: Iteration 8 done, Reward 1.26
[2024-02-13 13:58:30,662]: Iteration 9 done, Reward 1.12
Moviepy - Building video /Users/nicolasvila/workplace/uni/QREPS_ORIGINAL/tests/qreps_val/videos/CartPole-v1__cartpole__14__1707829027/rl-video-episode-729.mp4.
Moviepy - Writing video /Users/nicolasvila/workplace/uni/QREPS_ORIGINAL/tests/qreps_val/videos/CartPole-v1__cartpole__14__1707829027/rl-video-episode-729.mp4
Moviepy - Done !
Moviepy - video ready /Users/nicolasvila/workplace/uni/QREPS_ORIGINAL/tests/qreps_val/videos/CartPole-v1__cartpole__14__1707829027/rl-video-episode-729.mp4
[2024-02-13 13:58:31,246]: Iteration 10 done, Reward 0.51
[2024-02-13 13:58:31,710]: Iteration 11 done, Reward 0.47
[2024-02-13 13:58:32,196]: Iteration 12 done, Reward 0.47
[2024-02-13 13:58:32,683]: Iteration 13 done, Reward 0.48
[2024-02-13 13:58:33,599]: Iteration 14 done, Reward 1.37
[2024-02-13 13:58:34,048]: Iteration 15 done, Reward 0.47
[2024-02-13 13:58:35,607]: Iteration 16 done, Reward 2.78
[2024-02-13 13:58:37,881]: Iteration 17 done, Reward 3.64
[2024-02-13 13:58:40,098]: Iteration 18 done, Reward 3.67
Moviepy - Building video /Users/nicolasvila/workplace/uni/QREPS_ORIGINAL/tests/qreps_val/videos/CartPole-v1__cartpole__14__1707829027/rl-video-episode-1000.mp4.
Moviepy - Writing video /Users/nicolasvila/workplace/uni/QREPS_ORIGINAL/tests/qreps_val/videos/CartPole-v1__cartpole__14__1707829027/rl-video-episode-1000.mp4
Moviepy - Done !
Moviepy - video ready /Users/nicolasvila/workplace/uni/QREPS_ORIGINAL/tests/qreps_val/videos/CartPole-v1__cartpole__14__1707829027/rl-video-episode-1000.mp4
[2024-02-13 13:58:42,991]: Iteration 19 done, Reward 4.28
[2024-02-13 13:58:45,677]: Iteration 20 done, Reward 4.00
[2024-02-13 13:58:47,722]: Iteration 21 done, Reward 3.73
[2024-02-13 13:58:50,698]: Iteration 22 done, Reward 4.86
[2024-02-13 13:58:53,263]: Iteration 23 done, Reward 4.22
[2024-02-13 13:58:56,087]: Iteration 24 done, Reward 4.60
[2024-02-13 13:58:58,816]: Iteration 25 done, Reward 4.53
[2024-02-13 13:59:01,048]: Iteration 26 done, Reward 3.75
[2024-02-13 13:59:03,929]: Iteration 27 done, Reward 5.06
[2024-02-13 13:59:06,711]: Iteration 28 done, Reward 4.68
Traceback (most recent call last):
  File "/Users/nicolasvila/workplace/uni/QREPS_ORIGINAL/tests/qreps_val/experiments/cartpole.py", line 121, in <module>
    train(qreps_config)
  File "/Users/nicolasvila/workplace/uni/QREPS_ORIGINAL/tests/qreps_val/experiments/cartpole.py", line 117, in train
    trainer.train(num_iterations=30, max_steps=500, number_rollouts=50)
  File "/Users/nicolasvila/workplace/uni/QREPS_ORIGINAL/tests/qreps_val/qreps/utilities/trainer.py", line 62, in train
    self.algo.update_policy(self.iter)
  File "/Users/nicolasvila/workplace/uni/QREPS_ORIGINAL/tests/qreps_val/qreps/algorithms/qreps.py", line 124, in update_policy
    self.optimize_loss(self.dual, optimizer=self.theta_opt)
  File "/Users/nicolasvila/workplace/uni/QREPS_ORIGINAL/tests/qreps_val/qreps/algorithms/abstract_algorithm.py", line 166, in optimize_loss
    optimizer.step(closure)
  File "/Users/nicolasvila/miniconda3/lib/python3.11/site-packages/torch/optim/optimizer.py", line 373, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nicolasvila/miniconda3/lib/python3.11/site-packages/torch/optim/optimizer.py", line 76, in _use_grad
    ret = func(self, *args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nicolasvila/miniconda3/lib/python3.11/site-packages/torch/optim/adam.py", line 143, in step
    loss = closure()
           ^^^^^^^^^
  File "/Users/nicolasvila/workplace/uni/QREPS_ORIGINAL/tests/qreps_val/qreps/algorithms/abstract_algorithm.py", line 161, in closure
    loss = loss_fn(observations, next_observations, rewards, actions)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nicolasvila/workplace/uni/QREPS_ORIGINAL/tests/qreps_val/qreps/algorithms/qreps.py", line 99, in dual
    return empirical_logistic_bellman(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nicolasvila/workplace/uni/QREPS_ORIGINAL/tests/qreps_val/qreps/utilities/elbe.py", line 30, in empirical_logistic_bellman
    ) + torch.mean((1 - discount) * v_func(features), 0)
                                    ^^^^^^^^^^^^^^^^
  File "/Users/nicolasvila/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nicolasvila/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nicolasvila/workplace/uni/QREPS_ORIGINAL/tests/qreps_val/qreps/valuefunctions/integrated_q_function.py", line 17, in forward
    q_values = self.q_func.forward_state(obs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nicolasvila/workplace/uni/QREPS_ORIGINAL/tests/qreps_val/qreps/valuefunctions/q_function.py", line 43, in forward_state
    return self.model(input)
           ^^^^^^^^^^^^^^^^^
  File "/Users/nicolasvila/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nicolasvila/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nicolasvila/miniconda3/lib/python3.11/site-packages/torch/nn/modules/container.py", line 215, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/Users/nicolasvila/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nicolasvila/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nicolasvila/miniconda3/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt